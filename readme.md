# RAG Stack Deployment

## Project Structure

documents/ # Drop your documents here (txt/md)
backend/ # FastAPI backend (RAG API)
embedding-worker/ # Watches documents, generates embeddings
frontend/ # Streamlit web UI (optional)
docker-compose.yml


## Getting Started

1. **Prepare your docs:**  
   Place plain text files (`.txt`, `.md`) into `documents/`.  
   *(Add PDF/Word support to the embedding worker as needed.)*

2. **Build and launch the stack:**

docker compose up -d


3. **Access services:**
- **Streamlit UI:** [http://localhost:8501](http://localhost:8501)
- **FastAPI (backend):** [http://localhost:8000/docs](http://localhost:8000/docs)
- **Qdrant dashboard:** [http://localhost:6333](http://localhost:6333)  
- **Ollama API:** [http://localhost:11434](http://localhost:11434)

4. **Roles:**
- Use header `X-Role: user` for basic questions.
- Use header `X-Role: admin` for admin actions (reindexing, etc).

5. **Add more doc types:**
- To handle PDFs/Word, extend `embedding-worker/worker.py` with libraries such as `pdfminer.six`, `python-docx`, or `unstructured`.

## Port Assignments

- **Ollama (LLM):** 11434
- **Qdrant:** 6333
- **Backend API:** 8000
- **Frontend (UI):** 8501

## Requirements

- Docker & Docker Compose
- NVIDIA GPU on host (for Ollama/Mixtral)

---

## FAQ

- **How do I add documents?**  
Just copy `.txt` or `.md` files into `documents/`. The system auto-indexes.

- **How do I ask questions?**  
Use the Streamlit UI, or POST to `/ask` on the backend API with your query and role.

- **How do I reindex?**  
Use the admin button in the UI or call `/admin/reindex` with `X-Role: admin`.

---

## Customization

- Extend the embedding worker to parse PDFs, DOCX, HTML, etc.
- Improve the backend to call Qdrant for chunk retrieval and Ollama for LLM answers.
- Secure with real authentication for production.

---

## Maintainers

- Project scaffold generated by [ChatGPT](https://openai.com/chatgpt) for Bali, August 2025.
