version: "3.8"

services:

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    environment:
      - OLLAMA_MODELS=/models
    volumes:
      - ollama_models:/models
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command: >
      sh -c "ollama serve & sleep 5 && ollama pull mixtral:8x22b"

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    volumes:
      - qdrant_data:/qdrant/storage
    ports:
      - "6333:6333"

  embedding-worker:
    build: ./embedding-worker
    container_name: embedding-worker
    restart: unless-stopped
    environment:
      - QDRANT_URL=http://qdrant:6333
      - DOCS_PATH=/documents
      - EMBEDDING_MODEL=BAAI/bge-m3
    volumes:
      - ./documents:/documents
    depends_on:
      - qdrant

  backend:
    build: ./backend
    container_name: rag-backend
    restart: unless-stopped
    environment:
      - QDRANT_URL=http://qdrant:6333
      - OLLAMA_URL=http://ollama:11434
      - DOCS_PATH=/documents
    volumes:
      - ./documents:/documents
    ports:
      - "8000:8000"
    depends_on:
      - qdrant
      - ollama

  frontend:
    build: ./frontend
    container_name: rag-frontend
    restart: unless-stopped
    ports:
      - "8501:8501"
    depends_on:
      - backend

volumes:
  ollama_models:
  qdrant_data:
